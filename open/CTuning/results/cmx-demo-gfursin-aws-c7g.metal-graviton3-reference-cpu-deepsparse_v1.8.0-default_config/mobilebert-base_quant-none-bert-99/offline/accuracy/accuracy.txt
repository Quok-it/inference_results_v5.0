{"exact_match": 84.00189214758751, "f1": 90.79118282730964}
Reading examples...
No cached features at '/home/ubuntu/MLC/repos/local/cache/get-git-repo_906e0869/inference/language/bert/eval_features.pickle'... converting from examples...
Creating tokenizer...
Converting examples to features...
Caching features at '/home/ubuntu/MLC/repos/local/cache/get-git-repo_906e0869/inference/language/bert/eval_features.pickle'...
Loading LoadGen logs...
Post-processing predictions...
Writing predictions to: /home/ubuntu/MLC/repos/local/cache/get-mlperf-inference-results-dir_5e13e72a/valid_results/ip_172_31_64_203-reference-cpu-deepsparse-vdefault-default_config/mobilebert-base_quant-none-bert-99/offline/accuracy/predictions.json
Evaluating predictions...

hash=883be2a9d2ba5c45fe95d8b7fb3ce08abac7391fd051121fa8258b4e3bcb661b
