# MLPerf Inference v5.0 NVIDIA-Optimized Implementations (Open Division)

## Overview

This document provides an overview of the NVIDIA-optimized implementations submitted for the MLPerf Inference v5.0 benchmark in the Open Division. The submission includes performance results for the Jetson AGX Thor system, focusing on the LLaMA2 70B model in the offline scenario.

## Submission System
- **System Name**: Jetson AGX Thor 128GB
- **Availability**: Preview
- **System details**: see systems json

## Benchmark Details

- **Model**: LLaMA2 70B (FP4 quantized)
- **Scenario**: Offline
- **Submission Category**: Open Division
- **Software Stack**: TensorRT-LLM

## Conclusion

This submission demonstrates the capabilities of the Jetson AGX Thor system in handling large-scale models like LLaMA2 70B efficiently in an offline scenario. The results highlight NVIDIA's commitment to optimizing AI workloads for edge devices.