diff --git a/awq/modules/linear/gemm.py b/awq/modules/linear/gemm.py
index 23472a8..6c0e70d 100644
--- a/awq/modules/linear/gemm.py
+++ b/awq/modules/linear/gemm.py
@@ -88,7 +88,7 @@ class WQLinear_GEMM(nn.Module):
     ):
         super().__init__()
 
-        if w_bit not in [4]:
+        if w_bit not in [4, 8]:
             raise NotImplementedError("Only 4-bit are supported for now.")
 
         self.in_features = in_features
@@ -189,6 +189,8 @@ class WQLinear_GEMM(nn.Module):
         for col in range(intweight.shape[1] // pack_num):
             if awq_linear.w_bit == 4:
                 order_map = [0, 2, 4, 6, 1, 3, 5, 7]
+            elif awq_linear.w_bit == 8:
+                order_map = [0, 2, 1, 3]
             else:
                 raise NotImplementedError("Only 4-bit are supported for now.")
             for i in range(pack_num):
@@ -210,6 +212,8 @@ class WQLinear_GEMM(nn.Module):
         for col in range(zeros.shape[1] // pack_num):
             if awq_linear.w_bit == 4:
                 order_map = [0, 2, 4, 6, 1, 3, 5, 7]
+            elif awq_linear.w_bit == 8:
+                order_map = [0, 2, 1, 3]
             else:
                 raise NotImplementedError("Only 4-bit are supported for now.")
             for i in range(pack_num):
diff --git a/awq/utils/calib_data.py b/awq/utils/calib_data.py
index 2408cf3..0ffabf7 100644
--- a/awq/utils/calib_data.py
+++ b/awq/utils/calib_data.py
@@ -54,7 +54,7 @@ def get_calib_dataset(
             continue
         samples.append(sample)
         n_run += 1
-        if n_run == n_samples:
+        if n_run == -1: #n_samples:
             break
     # now concatenate all samples and split according to block size
     cat_samples = torch.cat(samples, dim=1)
