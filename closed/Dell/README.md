# MLPerf Inference v5.0 Implementations
This is a repository of Dell Technologies servers using optimized implementations for [MLPerf Inference Benchmark v5.0](https://github.com/mlcommons/inference).

# Implementations
## Benchmarks
**Please refer to /closed/NVIDIA for detailed instructions for NVIDIA GPU & Triton submissions, including performace guides, and instructions on how to run with new systems.** 

**Please refer to /closed/Intel for detailed instructions for Intel CPU submissions.**
  
# Dell Technologies Submission Systems

The systems that Dell has submitted on are:
- Dell PowerEdge R770
  - Intel GNR 86C CPU
- Dell PowerEdge R7725 
  - 2x H100-NVL-94GB
- Dell PowerEdge XE7745 
  - 8x H200-NVL-141GB
  - 8x L40S
- Dell PowerEdge XE9680L 
  - 8x H200-SXM-141GB
- Dell PowerEdge XE9680 
  - 8x H100-SXM-80GB
  - 8x H200-SXM-141GB
  - 8x H100-SXM-80GB, VMware ESXi


